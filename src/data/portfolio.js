import RayTracer from "../images/portfolio/raytracer.png"
import Chronicle from "../images/portfolio/chronicle.png"
import Portfolio from "../images/portfolio/portfolio.png"
import Sudoku from "../images/portfolio/sudoku.png"
import TSE from "../images/portfolio/tse.png"
import TSECrawler from "../images/portfolio/tse/crawler.png"
import TSEIndexer from "../images/portfolio/tse/indexer.png"
import TSEIndexerFile from "../images/portfolio/tse/indexer_file.png"
import TSEQuerier from "../images/portfolio/tse/querier.png"
import SimpleBalls from "../images/portfolio/raytracer/1/SimpleBalls.png"
import ReflectingBalls from "../images/portfolio/raytracer/1/ReflectingBalls.png"
import RefractingBalls from "../images/portfolio/raytracer/1/RefractingBalls.png"
import JensenBox from "../images/portfolio/raytracer/1/JensenBox.png"
import QuadLight from "../images/portfolio/raytracer/1/QuadLight.png"
import ManyBalls from "../images/portfolio/raytracer/1/ManyBalls.png"
import Ajax from "../images/portfolio/raytracer/2/Ajax.png"
import BunnyDragons from "../images/portfolio/raytracer/2/BunnyDragons.png"
import LoewenfeildBox from "../images/portfolio/raytracer/2/LoewenfeildBox.png"
import LoewenfeildWhite from "../images/portfolio/raytracer/2/LoewenfeildWhite.png"
import NefertitiWhite from "../images/portfolio/raytracer/2/NefertitiWhite.png"
import SimpleGeometry from "../images/portfolio/raytracer/2/SimpleGeometry.png"
import SponzaBuddha from "../images/portfolio/raytracer/2/SponzaBuddha.png"
import AjaxTextured from "../images/portfolio/raytracer/3/AjaxTextured.png"
import Earth from "../images/portfolio/raytracer/3/Earth.png"
import FresnelBlendBlue from "../images/portfolio/raytracer/3/FresnelBlendBlue.png"
import FresnelBlendBlack from "../images/portfolio/raytracer/3/FresnelBlendBlack.png"
import LoewenfeildTextured from "../images/portfolio/raytracer/3/LoewenfeildTextured.png"
import NefertitiTextured from "../images/portfolio/raytracer/3/NefertitiTextured.png"
import Table from "../images/portfolio/raytracer/3/Table.png"
import Teapot from "../images/portfolio/raytracer/3/Teapot.png"
import Marble from "../images/portfolio/raytracer/3/Marble.png"
import TexturedBox from "../images/portfolio/raytracer/3/TexturedBox.png"
import AjaxNormals from "../images/portfolio/raytracer/4/AjaxNormals.png"
import OdysseyMATS from "../images/portfolio/raytracer/4/OdysseyMATS.png"
import Phong from "../images/portfolio/raytracer/4/Phong.png"
import VeachMATS from "../images/portfolio/raytracer/4/VeachMATS.png"
import BlinnPhong from "../images/portfolio/raytracer/5/BlinnPhong.png"
import JensenBoxNEE from "../images/portfolio/raytracer/5/JensenBoxNEE.png"
import OdysseyMIS from "../images/portfolio/raytracer/5/OdysseyMIS.png"
import VeachMIS from "../images/portfolio/raytracer/5/VeachMIS.png"
import VeachNEE from "../images/portfolio/raytracer/5/VeachNEE.png"
import Clock from "../images/portfolio/raytracer/final/Clock.png"
import Oren20 from "../images/portfolio/raytracer/final/Oren20.png"
import Oren100 from "../images/portfolio/raytracer/final/Oren100.png"
import Final from "../images/portfolio/raytracer/final/Final.png"
import ShinyGeometry from "../images/portfolio/raytracer/final/ShinyGeometry.png"
import Stakeholders from "../images/portfolio/chronicle/Stakeholders.png"
import EmpathyMaps from "../images/portfolio/chronicle/EmpathyMaps.png"
import GenZ from "../images/portfolio/chronicle/GenZ.png"
import Boomer from "../images/portfolio/chronicle/Boomer.png"
import Solutions from "../images/portfolio/chronicle/Solutions.png"
import Sketch0 from "../images/portfolio/chronicle/Sketch0.png"
import Sketch1 from "../images/portfolio/chronicle/Sketch1.png"
import Sketch2 from "../images/portfolio/chronicle/Sketch2.png"
import Sketch3 from "../images/portfolio/chronicle/Sketch3.png"
import Sketch4 from "../images/portfolio/chronicle/Sketch4.png"
import Grey0 from "../images/portfolio/chronicle/Grey0.png"
import Grey1 from "../images/portfolio/chronicle/Grey1.png"
import Grey2 from "../images/portfolio/chronicle/Grey2.png"
import Grey3 from "../images/portfolio/chronicle/Grey3.png"
import Grey4 from "../images/portfolio/chronicle/Grey4.png"
import Mood from "../images/portfolio/chronicle/Mood.png"
import Hifi0 from "../images/portfolio/chronicle/Hifi0.png"
import Hifi1 from "../images/portfolio/chronicle/Hifi1.png"
import Hifi2 from "../images/portfolio/chronicle/Hifi2.png"
import Hifi3 from "../images/portfolio/chronicle/Hifi3.png"
import Hifi4 from "../images/portfolio/chronicle/Hifi4.png"
import Final0 from "../images/portfolio/chronicle/Final0.png"
import Final1 from "../images/portfolio/chronicle/Final1.png"
import Creator from "../images/portfolio/sudoku/creator.png"
import GUI from "../images/portfolio/sudoku/GUI.png"
import Play from "../images/portfolio/sudoku/play.png"
import Server from "../images/portfolio/sudoku/server.png"
import ServerOutput from "../images/portfolio/sudoku/serveroutput.png"
import Solver from "../images/portfolio/sudoku/solver.png"


export const portfolio = [
    {
        image: Portfolio,
        tags: ["Programming"],
        title: "Personal Website",
        date: "July 2022 - Present",
        people: "Just Me!",
        class: "Personal",
        tools: "React JS, CSS, Figma",
        description: "My very own personal website!",
        link: "/portfolio/website",
        page: {
            overview: "This is my very own personal website! Take a look at how I designed and built it here by checking out the Figma page and GitHub repository.",
            links: {
                github: "https://github.com/danielwestphal/danielwestphal",
                figma: "https://www.figma.com/file/7bqWKjDGBYeyBMLNIxCUd0/Personal-Website?node-id=0%3A1"
            },
            structure: [
            ]
        }
    },
    {
        image: Chronicle,
        tags: ["UI / UX"],
        title: "Chronicle",
        date: "April - June 2022 (3 weeks)",
        people: "Me, Justin Chong",
        class: "COSC 25.01: UI UX Design",
        tools: "Figma, UX Research",
        description: "A tablet app where family members can create collaborative digital stories to preserve precious memories.",
        link: "/portfolio/chronicle",
        page: {
            overview: "For our final in UI/UX Design, we embarked on a project to design a digital application to bridge generations. We began by conducting user experience research. Then we created grayscales before making a style guide and adding color. After we developed our initial Figma prototype we conducted user testing. We made revisions based on feedback and then presented our final design at Dartmouth’s Technigala.",
            links: {
                figma: "https://www.figma.com/file/UN2AQC525WpNJZtvke3sRk/Final_Chong_Westphal?node-id=203%3A3701",
                medium: "https://medium.com/@daniel.e.westphal.23/chronicle-ffe2deadd2bf"
            },
            structure: [
                {
                    type: "divider",
                    title: "Process"
                },
                {
                    type: "section",
                    title: "Overview",
                    subtitle: "Shedding more light on the generational divide",
                    description: "We conducted sociological, quantitative, and qualitative research on the differences and similarities between four key generations: Baby Boomers, Generation X, Millennials, and Generation Z. We found that Boomers as a whole tend to use technology to help create their desired lifestyle rather than allowing technology to shape their whole existence. Generation Z has grown up with digital technology their whole lives and tend to learn more through direct observation and active hands-on participation."
                },
                {
                    type: "emptySection",
                    description: "Our challenge was to create an interface that adapted to the needs and expectations of two vastly different generations with stark contrasts in technological literacy."
                },
                {
                    type: "emptySection",
                    description: "This lead us to our three design specifications"
                },
                {
                    type: "subSection",
                    title: "1. Accessible",
                    description: "We want our interface to be accessible to users of all age groups, as well as for those with color vision deficiency"
                },
                {
                    type: "subSection",
                    title: "2. Delightful",
                    description: "We strive to bring users an effortless sense of delight and joy, capturing the essence of childlike wonder"
                },
                {
                    type: "subSection",
                    title: "3. Intuitive",
                    description: "For our target audience of grandparents and grandchildren, we want our user flows to be intuitive and frictionless"
                },
                {
                    type: "divider",
                    title: "User Experience (UX) Research"
                },
                {
                    type: "section", title: "Stakeholders",
                    subtitle: "Who should we make sure to consider during the design process",
                    description: "We started by creating a stakeholder matrix to better visualize the people and organizations involved in intergenerational communication."
                },
                {
                    type: "inlineImage",
                    image: Stakeholders,
                    caption: "Stakeholder Map based on Power and Interest"
                },
                {
                    type: "section", title: "User Interviews",
                    subtitle: "Who we spoke to and what we learned",
                    description: "While ideating solutions, we initially focused on a digital app that would connect students who needed qualitative research/interviews for school projects and paper with older generations who could tell their personal stories and experiences. We were drawn towards this solution at first because we thought we were harnessing two generations’ needs for mutual benefit: 1) younger generations need to hear personal stories of big historical events from older people and 2) older generations who wanted to pass down stories and insights from their life to younger people."
                },
                {
                    type: "emptySection",
                    description: "However, after we conducted our user interviews, we realized that we had to pivot and come back to the drawing board. Targeting groups from our stakeholder matrix, we held four user interviews with two Boomers and two Gen Z’s. From our user interviews, we gathered a few key takeaways:"
                },
                {
                    type: "subSection",
                    title: "1. Privacy",
                    description: "Grandparents are not inclined to share stories with strangers"
                },
                {
                    type: "subSection",
                    title: "2. Family",
                    description: "There is something special about sharing stories within a family"
                },
                {
                    type: "subSection",
                    title: "3. Engagement",
                    description: "Kids often get distracted when listening to stories unless the story is very engaging"
                },
                {
                    type: "emptySection",
                    description: "We then created empathy maps so that we could better understand and empathize with our users."
                },
                {
                    type: "inlineImage",
                    image: EmpathyMaps,
                    caption: "Empathy maps for our four user tests"
                },
                {
                    type: "section",
                    title: "User Profiles",
                    subtitle: "Who are our users",
                    description: "Based on our user interviews, we also created user profiles for our two target user groups. This helped us solidify and concretize the needs, expectations, and motivations of our users."
                },
                {
                    type: "emptySection",
                    description: "We also identified pain points for each of our user groups in currently connecting with and understanding other generations."
                },
                {
                    type: "inlineImage",
                    image: GenZ,
                    caption: "User profile for Generation Z"
                },
                {
                    type: "subSection",
                    title: "1. Quality Time",
                    description: "Children crave quality time with their grandparents, who generally don’t live with them at home"
                },
                {
                    type: "subSection",
                    title: "2. Attention",
                    description: "Kids have short attention spans and need a product that captures, engages, and maintains their attention"
                },
                {
                    type: "subSection",
                    title: "3. Relating",
                    description: "Children find it difficult relating to their grandparents and starting and maintaining conversations with them"
                },
                {
                    type: "inlineImage",
                    image: Boomer,
                    caption: "User profile for Boomers"
                },
                {
                    type: "section",
                    title: "Solutions",
                    subtitle: "Refining the scope and brainstorming solutions",
                    description: "Based off of our UX research, we formulated our final how might we question:"
                },
                {
                    type: "quote",
                    quote: "How might we help connect generations within families?"
                },
                {
                    type: "emptySection",
                    description: "After we finalized our how might we question, we brainstormed solutions and categorized them based on how feasible and original they are."
                },
                {
                    type: "inlineImage",
                    image: Solutions,
                    caption: "2 x 2 for potential solutions to our how might we question"
                },
                {
                    type: "emptySection",
                    description: "We ended up going with the most feasible and original solution we came up with: a tablet app where grandparents and grandchildren can make collaborative digital stories where one person records the pages of the story and the other draws illustrations for it."
                },
                {
                    type: "divider",
                    title: "User Interface (UI) Design"
                },
                {
                    type: "section",
                    title: "User Flow",
                    subtitle: "How does the user navigate the app",
                    description: "When making our sketches we made sure to keep in mind our design specifications. We consistently iterated on our greyscales to make the best design possible."
                },
                {
                    type: "emptySection",
                    description: "Throughout our design process, we would revisit the Designer’s Critical Alphabet to ensure we were designing for groups typically excluded from the design process. Keeping this in mind during the process manifested itself in several ways:"
                },
                {
                    type: "subSection",
                    title: "Large Buttons",
                    description: "We used large buttons to make our app more accessible towards younger users (who might not have fully developed hand-eye coordination) and older users (who might have visual impairments and/or fine-motor limitations)."
                },
                {
                    type: "subSection",
                    title: "Icons",
                    description: "We used icons and illustrations when possible in conjunction with text to make our app more accessible towards people that have dyslexia or other reading disabilities."
                },
                {
                    type: "subSection",
                    title: "AAA Accessible Text",
                    description: "We wanted to ensure that our app was accessible to the highest degree"
                },
                {
                    type: "emptySection",
                    description: "We started off by developing a user flow:"
                },
                {
                    type: "emptySection",
                    description: "The app begins on the landing page."
                },
                {
                    type: "inlineImage",
                    image: Sketch0,
                    caption: "Empty state and landing flow"
                },
                {
                    type: "emptySection",
                    description: "From there, they can create a new book and choose whether their partner is with me or far away. While our app is primarily made for grandparents and grandchildren who are disconnected by large physical distances, we wanted to create a flow for those who are on the app together."
                },
                {
                    type: "emptySection",
                    description: "For partners who are far away from each other, users connect with their partner through audio. We wanted our users to be able to talk to each other over the app so the artist who illustrates the story can ask more questions and hold a conversation with their partner."
                },
                {
                    type: "emptySection",
                    description: "From there, users choose whether they will act as the storyteller or the artist for the story. Our primary thought was to have grandparents be the storyteller since this app functions to allow older generations pass down stories to their grandchildren and grandchildren be the artist since young children tend to be more creative, free-flowing with ideas, and artistically inclined. However, we wanted to give users the option to choose their roles to give them more freedom and allow children to tell stories of their life to their grandparents."
                },
                {
                    type: "emptySection",
                    description: "When users choose the storyteller flow, they can choose whether they want the app to give them a randomized prompt if they have no stories at the top of their head that they want to tell. We decided to imitate a casino machine spinning to spit out a prompt for users to give a feeling of delight, excitement, and anticipation in getting a prompt, but we also gave users the option to spin again in case they didn’t like the prompt they initially got. We also give storytellers the option to write a story if they have one in mind already."
                },
                {
                    type: "inlineImage",
                    image: Sketch1,
                    caption: "Setting up the story flow"
                },
                {
                    type: "emptySection",
                    description: "If users choose the artist flow, they can talk with their partner to decide on these, but we ultimately left it up to the storyteller because they would know more about the story they want to tell."
                },
                {
                    type: "emptySection",
                    description: "Once they start creating their story, the storyteller records the first page of the story, and the app transcribes the audio into text on the page. Taking into consideration that the AI may mess up the transcription or users may want to add more details, storytellers can re-record the page."
                },
                {
                    type: "inlineImage",
                    image: Sketch3,
                    caption: "Storyteller flow"
                },
                {
                    type: "emptySection",
                    description: "Once the first page is recorded, artists have three minutes to draw the scene using the tools, colors, and common graphics given to them. We decided not to give them infinite time to draw each page because that could cause them to spend too long on one page, which could leave the storyteller spending too long simply waiting for the artist to finish drawing and de-motivate users from finishing the book. A limited time to draw each page would also enhance the fast-paced, exciting nature of the storytelling, challenge artists’ creativity, and emphasize the importance of constant communication between the storyteller and artist. While the artist draws, the storyteller can see the art being drawn on their end in real-time, allowing the storyteller to give words of encouragement and feedback to the artist."
                },
                {
                    type: "inlineImage",
                    image: Sketch2,
                    caption: "Artist flow"
                },
                {
                    type: "emptySection",
                    description: "After three minutes are up, the storyteller can choose to add another page to their story or finish the book."
                },
                {
                    type: "emptySection",
                    description: "When they finish the story, they can enter the title of the book and choose the color of the book cover. When the book is added to their bookshelf on the landing page, the amount of pages in the book corresponds to the amount of experience points they gain, and they see the experience progress bar increase. As they create more books, the plant on the landing page grows taller and blooms more flowers, making the landing page more aesthetically pleasing and beautiful the more they use the app."
                },
                {
                    type: "inlineImage",
                    image: Sketch4,
                    caption: "Ending flow"
                },
                {
                    type: "section",
                    title: "Greyscales",
                    subtitle: "Turning our sketches into designs",
                    description: "We then turned our sketches into grayscales."
                },
                {
                    type: "inlineImage",
                    image: Grey0,
                    caption: "Landing page greyscale"
                },
                {
                    type: "inlineImage",
                    image: Grey1,
                    caption: "Story set up greyscale"
                },
                {
                    type: "inlineImage",
                    image: Grey2,
                    caption: "Artist greyscale"
                },
                {
                    type: "inlineImage",
                    image: Grey3,
                    caption: "Storyteller greyscale"
                },
                {
                    type: "inlineImage",
                    image: Grey4,
                    caption: "Ending greyscale"
                },
                {
                    type: "section",
                    title: "Mood Board",
                    subtitle: "Creating a fun and playful app",
                    description: "We wanted our application to be fun and playful, yet at the same time not too childish as to deter older users from using it. We got inspiration from current market competitors for children’s tablet apps to get a sense of a kid-friendly UI. We concluded that bright colors and fun patterns for the background are essential, but creating a too chaotic or unorganized background pattern could be distracting and clash with the primary buttons and text on the screens."
                },
                {
                    type: "inlineImage",
                    image: Mood,
                    caption: "A fun and playful moodboard"
                },
                {
                    type: "emptySection",
                    description: "From the mood board, we began to play with different color schemes and background patterns, until we honed on an a primary and secondary color scheme to create a style guide, which is a document that dictates the colors, typography, call to action buttons, text fields, navigation elements, and iconography as a unified design language for the app."
                },
                {
                    type: "section",
                    title: "High Fidelity Mockups",
                    subtitle: "Adding color and making our app cleaner",
                    description: "We decided to create a fun, engaging landing page as a bookshelf of the different books the user has created with other people on the app. The landing page has an experience (XP) bar at the top that incentivizes users to create more books so they can level up, for example, from novice to intermediate storyteller."
                },
                {
                    type: "inlineImage",
                    image: Hifi0,
                    caption: "Empty state and landing hifi"
                },
                {
                    type: "inlineImage",
                    image: Hifi1,
                    caption: "Prompt choice hifi"
                },
                {
                    type: "inlineImage",
                    image: Hifi2,
                    caption: "Artist workflow hifi"
                },
                {
                    type: "inlineImage",
                    image: Hifi3,
                    caption: "Storyteller workflow hifi"
                },
                {
                    type: "inlineImage",
                    image: Hifi4,
                    caption: "End flow hifi"
                },
                {
                    type: "section",
                    title: "User Testing",
                    subtitle: "Bringing our HiFis back to our users",
                    description: "We posted our first draft of our prototype on UserTesting.com to gather feedback. We made sure that all of our users were grandparents by screening for users 55 years and older. Unfortunately, we could not test the app on children because UserTesting.com does not allow people under 18 years old to be users. We asked our users to navigate through different flows while rating the difficulty and intuitiveness along the way. At the end, we asked them several summary questions. From our user feedback, all of our users found the app incredibly easy to use and intuitive, but we also gained several key learnings that were the targets of our revisions."
                },
                {
                    type: "subSection",
                    title: "1. Unauthentic Style",
                    description: "Users said the style of the app was unauthentic to what a kid would want. Furthermore, they felt that the vector art of the example artist’s illustrations were not what a kid would draw. We thus iterated the UI further to create a more joyful, bright color scheme and drew the art on an iPad and imported the graphics in to give the drawings more of an authentic look."
                },
                {
                    type: "subSection",
                    title: "2. Graphics Tool",
                    description: "Users felt like it would be useful for the artist on the app to have some preset graphics to use in their drawings. We thus implemented some common graphics on the artist flow that users can drag and drop them into the page."
                },
                {
                    type: "subSection",
                    title: "3. Reading Library",
                    description: "Users wondered where books they made that did not fit on the bookshelf would go. A reading library where users would see all of their previous books and be able to favorite books to put on their bookshelf."
                },
                {
                    type: "inlineImage",
                    image: Final0,
                    caption: "Landing flow after user testing"
                },
                {
                    type: "inlineImage",
                    image: Final1,
                    caption: "Artist flow after user testing"
                },
                {
                    type: "divider",
                    title: "Reflections"
                },
                {
                    type: "section",
                    title: "Future Improvements",
                    subtitle: "What we would have done if we had more time",
                    description: "If we had more time to work on this project, we would focus work on several parts of the app:"
                },
                {
                    type: "subSection",
                    title: "Reading Library",
                    description: "Implementing the aforementioned “reading library”"
                },
                {
                    type: "subSection",
                    title: "Graphics Tool",
                    description: "Extending the graphics tool to allow users to save their own graphics for later use"
                }, 
                {
                    type: "subSection",
                    title: "More Testing",
                    description: "Continuing to push our UI by conducting more user testing, especially on children"
                },
                {
                    type: "section",
                    title: "Takeaways",
                    subtitle: "Lessons learned for the future",
                    description: "After pouring lots of time and effort into this project, we came out of it with many personal takeaways for future design projects. Here are a few of them:"
                },
                {
                    type: "subSection",
                    title: "Our users’ needs are typically not what we think they are",
                    description: "We initially assumed in our user research and ideation phase that grandparents would be motivated to share their stories with strangers to pass on life advice and wisdom to the next generation. We discovered in our interviews that they would be hesitant to do this, especially because older generations are skeptical of the implications of privacy and confidentiality with digital technology."
                },
                {
                    type: "subSection",
                    title: "Designing the interface step by step can blind us to what may not be intuitive to first-time users",
                    description: "When we were designing the flows from scratch and working through multiple iterations of each screen, it can be easy to fall into the trap of thinking that certain aspects are intuitive when we’ve been building the design from scratch. It took some reflection and critical thinking to attempt to put ourselves in the shoes of a first-time user opening the app for the first time."
                },
                {
                    type: "subSection",
                    title: "Disabilities can be reframed as vantage points for the design process",
                    description: "We are both color blind designers with deuteranopia and protanomaly, which made designing the UI more difficult. Thus, we relied on user testing and feedback from other designers to aid our UI decisions. In the end, our design ended up being colorblind accessible since it had to be accessible for us to design it!"
                },
            ]
        }
    },
    {
        image: Sudoku,
        tags: ["Programming"],
        title: "Sudoku Solver",
        date: "May - June 2022 (3 weeks)",
        people: "Me, Three Others",
        class: "COSC 50: Software Design & Implementation",
        tools: "C, Bash, Git",
        description: "Sudoku solver and creator utilizing TCP server/client architecture.",
        link: "/portfolio/sudoku",
        page: {
            overview: "For our final project for CS50, my group of four was assigned to build a sudoku creator (that would generate a board with only one solution) and solver. I was responsible for implementing the sudoku solver, server/client architecture, and larder size boards. Testing was also implemented.",
            links: {
                github: "mailto:dew.23@dartmouth.edu"
            },
            structure: [
                { type: "divider", title: "Features" },
                {
                    type: "section",
                    title: "Solver",
                    subtitle: "./sudoku solver",
                    description: "The sudoku solver solves any size sudoku board. The user inputs the size of the board and the board itself and the program outputs a solution for it. It finds a solution by iterating through the board and when it finds an empty tile collecting all the possible digits that could go there. It then chooses a digit at random and continues. If a solution does not exist it backtracks and tries a new number. If there are no more possible numbers it returns that there's no solution."
                },
                {
                    type: "inlineImage",
                    image: Solver,
                    caption: "A sample usage of the solver"
                },
                {
                    type: "section",
                    title: "Creator",
                    subtitle: "./sudoku create",
                    description: "The creator uses the solver to generate new sudoku boards. It starts by getting a filled in sudoku board by passing an empty board to the solver. Then it randomly chooses tiles and sees if there is still a unique solution for the board if you were to remove it. If there would still be a unique solution, it removes it and continues."
                },
                {
                    type: "inlineImage",
                    image: Creator,
                    caption: "A sample usage of the creator"
                },
                {
                    type: "section",
                    title: "Client / Server",
                    subtitle: "./sudoku_server",
                    description: "We integrated the creator with a server. The client (user) sends a request to the server with the size of the sudoku board and then the server creates a board of that size and sends it back."
                },
                {
                    type: "inlineImage",
                    image: Server,
                    caption: "The server uses a TCP architecture and the Berkeley Sockets API"
                },
                {
                    type: "inlineImage",
                    image: ServerOutput,
                    caption: "The server outputs logging information to show its progress"
                },
                {
                    type: "section",
                    title: "Play Mode",
                    subtitle: "./sudoku play",
                    description: "We also created a 'play' mode that allows the user to actively solve a solution in real time."
                },
                {
                    type: "inlineImage",
                    image: Play,
                    caption: "A sample play mode"
                },
                {
                    type: "section",
                    title: "GUI",
                    subtitle: "the interface we made to visualize the process",
                    description: "Lastly, we created a GUI in Python so that people could see the sudoku board in a nicer format than the command line."
                },
                {
                    type: "inlineImage",
                    image: GUI,
                    caption: "The GUI showing a solved sudoku board; it shows the difference between user inputted numbers and numbers that are parts of the board"
                },

            ]
        }
    },
    {
        image: TSE,
        tags: ["Programming"],
        title: "Tiny Search Engine",
        date: "April - May 2022 (4 weeks)",
        people: "Just Me!",
        class: "COSC 50: Software Design & Implementation",
        tools: "C, Bash",
        description: "A search engine that crawls through web pages, indexes them, and queries them.",
        link: "/portfolio/tse",
        page: {
            overview: "This Tiny Search Engine (tse) was made for my final individual project for COSC 50. The purpose of the tse is to simulate how search engines work (albeit on a smaller and simpler scale). The tse is able to crawl through and download webpages from a source, index the words on those pages, and then query and rank the pages based off of search terms. Testing was implemented for every component.",
            links: {
                github: "mailto:dew.23@dartmouth.edu"
            },
            structure: [
                { type: "divider", title: "Features" },
                {
                    type: "section",
                    title: "Crawler",
                    subtitle: "./crawler seedURL pageDirectory max_depth",
                    description: "The crawler takes in a designated seedURL and crawls all pages reachable from that URL up to a specified max_depth. The HTML files of the website that it crawls through are saved to the pageDirectory."
                },
                {
                    type: "inlineImage",
                    image: TSECrawler,
                    alt: "Crawler Demo",
                    caption: "The output of the crawler running on a contained seed url"
                },
                {
                    type: "section",
                    title: "Indexer",
                    subtitle: "./indexer pageDirectory indexFilename",
                    description: "The TSE indexer is a standalone program that reads the document files produced by the TSE crawler, builds an index, and writes that index to a file. An index contains a count of how many time every word appears in each page."
                },
                {
                    type: "inlineImage",
                    image: TSEIndexer,
                    alt: "Crawler Demo",
                    caption: "The output of the indexer running on the crawled webpages from above"
                },
                {
                    type: "inlineImage",
                    image: TSEIndexerFile,
                    alt: "Crawler Output File",
                    caption: "The output.out file generated; we see webpage number 4 contains the word eniac one time"
                },
                {
                    type: "section", title: "Querier",
                    subtitle: "./querier pageDirectory indexFilename",
                    description: "The TSE Querier reads the index produced by the Indexer and the page files produced by the Crawler, to interactively answer written queries entered by the user. Queries can contain logic (e.g. dogs OR cats, dogs AND cats) and results are returned to the user ranked."
                },
                {
                    type: "inlineImage",
                    image: TSEQuerier,
                    alt: "Querier Demo",
                    caption: "The output of the querier; fuzzquery generates random queries to search for to facilitate testing"
                }
            ]
        }
    },
    {
        image: RayTracer,
        tags: ["Programming"],
        title: "Ray Tracer",
        date: "September - November 2021 (10 weeks)",
        people: "Me, Abigail Owen",
        class: "COSC 87: Rendering Algorithms",
        tools: "C++, Blender",
        description: "Custom ray-tracing algorithm to generate photorealistic images.",
        link: "/portfolio/ray-tracer",
        page: {
            overview: "This ray tracer is the cumulation of a terms worth of work in COSC 87. A ray tracer simulates the path of light in a scene to create a photorealistic image. Most scenes shown here were pre-arranged, but, for several, I tried my hand at creating my own scene in Blender. It was done entirely independently, with the exception of the final project which was done with a partner.",
            links: {
                github: "mailto:dew.23@dartmouth.edu"
            },
            structure: [
                { type: "divider", title: "Features" },
                {
                    type: "section", title: "Simple Ray Tracing",
                    subtitle: "A very basic ray tracer",
                    description: "The first step in this project was creating a basic renderer. I did this by using a backward ray tracing technique. Since only a very small percentage of light in a scene will actually hit an eye, it is more efficient to start tracing photons of light from the eye and 'reverse calculate' what the color of that light would be. We can do this many times and take an average of the color to make the image look better."
                },
                {
                    type: "emptySection",
                    description: "We can determine the color of an individual photon by implementing algorithms that determine the direction that light scatters and the color attenuation of that light based on the shape, material, and color of an object."
                },
                {
                    type: "emptySection",
                    description: "I first implemented a collision algorithm for spheres and an attenuation algorithm for lambertian (matte) materials."
                },

                {
                    type: "inlineImage",
                    image: SimpleBalls,
                    caption: "A simple render of two lambertian spheres"

                },
                {
                    type: "emptySection",
                    description: "I then implemented a metal material that acts similarly to a mirror."
                },
                {
                    type: "inlineImage",
                    image: ReflectingBalls,
                    caption: "A simple render of a metal sphere and a lambertian sphere"
                },
                {
                    type: "emptySection",
                    description: "Lastly, I implemented a dielectric (glass-like) material, which reflects and refracts light depending on the angle of incidence and other factors."
                },
                {
                    type: "inlineImage",
                    image: RefractingBalls,
                    caption: "A simple render of a dielectric sphere and a lambertian sphere"
                },
                {
                    type: "emptySection",
                    description: "Now that we've implemented some basic material types we can make some more complicated scenes."
                },
                {
                    type: "inlineImage",
                    image: JensenBox,
                    caption: "A 'Jensen Box'"
                },
                {
                    type: "inlineImage",
                    image: QuadLight,
                    caption: "A series of marbles with a small light source"
                },
                {
                    type: "inlineImage",
                    image: ManyBalls,
                    caption: "Many marbles in an open area, focused on the middle"
                },
                {
                    type: "section", title: "Efficient Ray Tracing",
                    subtitle: "Making the ray tracer faster using bounding volume hierarchies",
                    description: "Scenes take increasingly longer to render the more objects you put in them since you have to check for more and more collisions. Since I wanted to be able to render mesh objects (composed of thousands of triangles), I have to make the algorithm more efficient."
                },
                {
                    type: "inlineImage",
                    image: SimpleGeometry,
                    caption: "A simple example of how meshes can be used to create shapes we haven't implemented"
                },
                {
                    type: "emptySection",
                    description: "I do this by creating 'bounding volume heirarchies'. The idea behind this is that if a light ray is on the right side of the scene, there is no point in checking for any collisions on the left side of the scene. This simple observation makes it so that doubling the number of objects in a scene only increases the render time by a small percentage (<10%)."
                },
                {
                    type: "emptySection",
                    description: "After implementing a collision algorithm for triangles and making our collision checker more efficient, we can render more complicated and interesting scenes."
                },
                {
                    type: "inlineImage",
                    image: Ajax,
                    caption: "A sculpture of Ajax using a mesh"
                },
                {
                    type: "inlineImage",
                    image: LoewenfeildWhite,
                    caption: "A sculpture of Loewenfeld using a mesh"
                },
                {
                    type: "inlineImage",
                    image: LoewenfeildBox,
                    caption: "A sculpture of Loewenfeld in a box"
                },
                {
                    type: "inlineImage",
                    image: NefertitiWhite,
                    caption: "A sculpture of Nefertiti using a mesh"
                },
                {
                    type: "inlineImage",
                    image: BunnyDragons,
                    caption: "A scene consisting of bunnies and dragons"
                },
                {
                    type: "inlineImage",
                    image: SponzaBuddha,
                    caption: "A scene consisting of statue of Buddha in a museum"
                },
                {
                    type: "section", title: "Textures",
                    subtitle: "Implementing different textures, such as marble, checkerboard, custom, and fresnel blend",
                    description: "The next step in the project was to implement different textures. The way that a texture appears on an object depends on the shape of the object. Thus, we implement texture mapping for every shape which tells the renderer how a texture maps to a location on that shape."
                },
                {
                    type: "emptySection",
                    description: "I first implemented a checker pattern."
                },
                {
                    type: "inlineImage",
                    image: Teapot,
                    caption: "A checkered teapot in a box"
                },
                {
                    type: "emptySection",
                    description: "And then a marble texture."
                },
                {
                    type: "inlineImage",
                    image: Marble,
                    caption: "A marble on a marbled floor"
                },
                {
                    type: "emptySection",
                    description: "Lastly, I implemented image texturing. This lets a user specify an image to map to an object."
                },
                {
                    type: "inlineImage",
                    image: TexturedBox,
                    caption: "A textured box, where the texture wraps after it ends"
                },
                {
                    type: "inlineImage",
                    image: Earth,
                    caption: "A textured sphere of the earth (a globe)"
                },
                {
                    type: "inlineImage",
                    image: AjaxTextured,
                    caption: "A sculpture of Ajax, but now textured"
                },
                {
                    type: "inlineImage",
                    image: LoewenfeildTextured,
                    caption: "A sculpture of Loewenfeld, but now textured"
                },
                {
                    type: "inlineImage",
                    image: NefertitiTextured,
                    caption: "A sculpture of Nefertiti, but now textured"
                },
                {
                    type: "emptySection",
                    description: "I also implemented a new material called a Fresnel blend that is a mix of a lambertian and dielectric material."
                },
                {
                    type: "inlineImage",
                    image: FresnelBlendBlack,
                    caption: "A series of marbles with a black Fresnel blend"
                },
                {
                    type: "inlineImage",
                    image: FresnelBlendBlue,
                    caption: "A series of marbles with a blue Fresnel blend"
                },
                {
                    type: "emptySection",
                    description: "Finally, I tried my own hand at creating an original scene in Blender using meshes and textures."
                },
                {
                    type: "inlineImage",
                    image: Table,
                    caption: "My own scene: 'Table for One'"
                },
                {
                    type: "section", title: "Sampling Materials",
                    subtitle: "Using Monte Carlo integration to directly sample materials",
                    description: "I then implemented material sampling. Material sampling computes the attenuation and color of light reflected off of an object by computing the likelihood of a ray scattering in the direction that it does and attenuating the ray based on that probability. This is effectively using Monte Carlo simulations more explicity to build a more powerful renderer. This involves rewriting and adding to our materials to allow this to happen."
                },
                {
                    type: "emptySection",
                    description: "In order to use this material sampling we have to create an integrator. An integrator essentially tells the renderer how to render a scene and compute the colors of pixels. For example, one integrator I built computes the color of an object based only on the direction it hits it."
                },
                {
                    type: "inlineImage",
                    image: AjaxNormals,
                    caption: "An example of an integrator based on the normals"
                },
                {
                    type: "emptySection",
                    description: "I then built out the integrator to use for the material sampling."
                },
                {
                    type: "inlineImage",
                    image: OdysseyMATS,
                    caption: "A scene created using material sampling"
                },
                {
                    type: "inlineImage",
                    image: VeachMATS,
                    caption: "Another scene created using material sampling"
                },
                {
                    type: "emptySection",
                    description: "I also implemented a Phong (glossy) material."
                },
                {
                    type: "inlineImage",
                    image: Phong,
                    caption: "A scene containing phong spheres using material sampling"
                },
                {
                    type: "section", title: "Sampling Lights",
                    subtitle: "Using Monte Carlo integration to directly sample lights",
                    description: "My next step was to also implement sampling lights using the same approach as discussed above. I also implemented a new integrator for this, called a next event estimator."
                },
                {
                    type: "inlineImage",
                    image: VeachNEE,
                    caption: "A significantly less noisy image produced using next event estimation"
                },
                {
                    type: "inlineImage",
                    image: JensenBoxNEE,
                    caption: "A significantly less noisy Jensen Box produced using next event estimation"
                },
                {
                    type: "emptySection",
                    description: "Next, I built an integrator called multiple importance sampling that combines next event estimation with material sampling to produce less noisy images."
                },
                {
                    type: "inlineImage",
                    image: OdysseyMIS,
                    caption: "A very clean image produced using multiple importance sampling"
                },
                {
                    type: "inlineImage",
                    image: VeachMIS,
                    caption: "A very clean image produced using multiple importance sampling"
                },
                {
                    type: "emptySection",
                    description: "Lastly, I implemented one more material called Blinn Phong, which is a more complicated, rougher looking varient of the phong material."
                },
                {
                    type: "inlineImage",
                    image: BlinnPhong,
                    caption: "A series of blinn phong spheres"
                },
                {
                    type: "section", title: "Final Project",
                    subtitle: "Adding additional functionality and creating our own scene (partner project)",
                    description: "The theme for the final project was 'it's what's on the inside that counts'. My partner and I decided to create a scene of a person looking into a mirror and seeing their own skeleton. We also implemented some new features, including a disk feature with texture mapping."
                },
                {
                    type: "inlineImage",
                    image: Clock,
                    caption: "A disk shape with a clock texture mapped to it"
                },
                {
                    type: "emptySection",
                    description: "We also created microfacet textures, which are textures that occur when light gets trapped in the surface of a rough material."
                },
                {
                    type: "inlineImage",
                    image: Oren20,
                    caption: "Microfacet material with a low roughness coefficient"
                },
                {
                    type: "inlineImage",
                    image: Oren100,
                    caption: "Microfacet material with a high roughness coefficient"
                },
                {
                    type: "emptySection",
                    description: "We also implemented a shinier metal material"
                },
                {
                    type: "inlineImage",
                    image: ShinyGeometry,
                    caption: "Shiny chromatic material"
                },
                {
                    type: "emptySection",
                    description: "We put these all together to create our final render. We created the scene ourselves using Blender."
                },
                {
                    type: "inlineImage",
                    image: Final,
                    caption: "The final render"
                },
            ]
        }
    }

]

/*
Strucutre:

{
    image: "link to image",
    tags: ["Digital Art", "UI / UX", "Programming"],
    title: "Sculpture",
    date: "Fall 2021",
    description: "Custom ray-tracing algorithm for dielectric, matte, and reflective surfaces."
}


*/